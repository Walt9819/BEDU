print("hello World")
sqrt(10)
log(1)
exp(2)
?mean
??mean
class(12)
typeof(12)
?matrix
max(100/4, 108/5, 200/20, sqrt(81), 35)
install.packages("dplyr")
library(dplyr)
saludo <- function(nombre) {}
saludo <- function(nombre) { return(paste("Hola", nombre)) }
saludo("Walt")
q()
install.packages("shiny")
library(shiny)
runExample("01_hello")
q()
x = c(4000, 9000, 9000, 10000); mean(x)
median(x)
library(DescTools)
install.packages("DescTools")
library(DescTools)
Mode(x) # mode es diferente de Mode (Case sensitive)
x <- c(29, 13, 62, 4, 63, 96, 1, 90, 50, 46)
x <- c(29, 13, 62, 4, 63, 96, 1, 90, 50, 46)
quantile(x, 0.25) # cuantil del 25%
quantile(x, c(0.25,0.50,0.75)) # Cuartiles
boxplot(x)
quantile(x, seq(0.1,0.9, by = 0.1)) # Deciles
x.sort()
x.sort
sort(x)
mean(c(13, 29))
IQR(x)
quantile(x, probs = 0.75) - quantile(x, probs = 0.25)
quantile(x, probs = 0.75) - quantile(x, probs = 0.25)
var(x)
sd(x)
sqrt(var(x))
#Calcule, la media, mediana y moda de los valores en x
mean(x)
set.seed(134)
x <- round(rnorm(1000, 175, 6), 1)
#Calcule, la media, mediana y moda de los valores en x
mean(x)
median(x)
Mode(x)
#Obtenga los deciles de los números en x
quartile(x, seq(0.1, 0.9, by=0.1))
#Obtenga los deciles de los números en x
quantile(x, seq(0.1, 0.9, by=0.1))
#Encuentre la rango intercuartílico, la desviación estándar y varianza muestral de las mediciones en x
IQR(x)
sd(x)
var(x)
#Calcule, la media, mediana y moda de los valores en x
mean(x)
median(x)
Mode(x)
#Obtenga los deciles de los números en x
quantile(x, seq(0.1, 0.9, by=0.1))
#Encuentre la rango intercuartílico, la desviación estándar y varianza muestral de las mediciones en x
IQR(x)
sd(x)
var(x)
x
mode(x)
str(iris)
summary(1:100)
summary(mtcars)
set.seed(57)
x <- rnorm(35)
e <- rnorm(35)
y <- 5 + 2*x + e
modelo <- lm(y~x)
summary(modelo)
head(mtcars)
tail(mtcars)
View(iris)
unique(iris$Species)
#Considere el data frame mtcars de R y utilice las funciones
str(mog)
#Considere el data frame mtcars de R y utilice las funciones
str(mpg)
#Considere el data frame mtcars de R y utilice las funciones
str(mtcars)
summary(mtcars)
#Considere el data frame mtcars de R y utilice las funciones
str(mtcars)
summary(mtcars)
head(mtcars)
head(mtcars)
getwd()
setwd("D:/Documentos/BEDU/mod2/sesion02")
suppressMessages(suppressWarnings(library(dplyr)))
url1 <- "https://data.humdata.org/hxlproxy/data/download/time_series_covid19_confirmed_global_narrow.csv?dest=data_edit&filter01=explode&explode-header-att01=date&explode-value-att01=value&filter02=rename&rename-oldtag02=%23affected%2Bdate&rename-newtag02=%23date&rename-header02=Date&filter03=rename&rename-oldtag03=%23affected%2Bvalue&rename-newtag03=%23affected%2Binfected%2Bvalue%2Bnum&rename-header03=Value&filter04=clean&clean-date-tags04=%23date&filter05=sort&sort-tags05=%23date&sort-reverse05=on&filter06=sort&sort-tags06=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv"
url2 <- "https://data.humdata.org/hxlproxy/data/download/time_series_covid19_deaths_global_narrow.csv?dest=data_edit&filter01=explode&explode-header-att01=date&explode-value-att01=value&filter02=rename&rename-oldtag02=%23affected%2Bdate&rename-newtag02=%23date&rename-header02=Date&filter03=rename&rename-oldtag03=%23affected%2Bvalue&rename-newtag03=%23affected%2Binfected%2Bvalue%2Bnum&rename-header03=Value&filter04=clean&clean-date-tags04=%23date&filter05=sort&sort-tags05=%23date&sort-reverse05=on&filter06=sort&sort-tags06=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_deaths_global.csv"
download.file(url = url1, destfile = "data/st19ncov-confirmados.csv", mode = "wb")
url1 <- "https://data.humdata.org/hxlproxy/data/download/time_series_covid19_confirmed_global_narrow.csv?dest=data_edit&filter01=explode&explode-header-att01=date&explode-value-att01=value&filter02=rename&rename-oldtag02=%23affected%2Bdate&rename-newtag02=%23date&rename-header02=Date&filter03=rename&rename-oldtag03=%23affected%2Bvalue&rename-newtag03=%23affected%2Binfected%2Bvalue%2Bnum&rename-header03=Value&filter04=clean&clean-date-tags04=%23date&filter05=sort&sort-tags05=%23date&sort-reverse05=on&filter06=sort&sort-tags06=%23country%2Bname%2C%23adm1%2Bname&tagger-match-all=on&tagger-default-tag=%23affected%2Blabel&tagger-01-header=province%2Fstate&tagger-01-tag=%23adm1%2Bname&tagger-02-header=country%2Fregion&tagger-02-tag=%23country%2Bname&tagger-03-header=lat&tagger-03-tag=%23geo%2Blat&tagger-04-header=long&tagger-04-tag=%23geo%2Blon&header-row=1&url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv"
download.file(url = url1, destfile = "data/st19ncov-confirmados.csv", mode = "wb")
download.file(url = url2, destfile = "data/st19ncov-muertes.csv", mode = "wb")
conf <- read.csv("data/st19ncov-confirmados.csv")
mu <- read.csv("data/st19ncov-muertes.csv")
conf <- read.csv("data/st19ncov-confirmados.csv")
mu <- read.csv("data/st19ncov-muertes.csv")
str(conf)
summary(conf)
head(conf)
unique(conf$Province.State)
Sconf <- conf[-1,]
Smu <- mu[-1,]
Sconf
head(Sconf)
Sconf <- conf[-1,]
Smu <- mu[-1,]
-1:10
Sconf <- select(Sconf, Country.Region, Date, Value) # País, fecha y acumulado de infectados
Sconf <- rename(Sconf, Country = Country.Region, Infectados = Value)
str(Sconf)
Sconf <- mutate(Sconf, Date = as.Date(Date, "%Y-%m-%d"), Infectados = as.numeric(as.character(Infectados)))
Sconf
str(Sconf)
Smu <- select(Smu, Country.Region, Date, Value) # Seleccionamos país, fecha y acumulado de muertos
Smu <- rename(Smu, Country = Country.Region, Muertos = Value) # Renombramos
Smu <- mutate(Smu, Date = as.Date(Date, "%Y-%m-%d"), Muertos = as.numeric(as.character(Muertos))) # Transformamos
summary(Sconf)
filter(Sconf, Infectados=max(Infectados))
filter(Sconf, Infectados==max(Infectados))
filter(Sconf, Infectados==min(Infectados))
filter(Sconf, Infectados==max(Infectados))
filter(Sconf, Country=="USA")
filter(Sconf, Country=="US")
Scm <- merge(Sconf, Smu) # Unimos infectados y muertos acumulados para cada fecha
Scm
mex <- filter(Scm, Country == "Mexico") # Seleccionamos sólo a México
mex
mex <- filter(mex, Infectados != 0) # Primer día de infectados
mex
mex <- filter(Scm, Country == "Mexico") # Seleccionamos sólo a México
mex <- filter(mex, Infectados != 0) # Primer día de infectados
mex
mex <- mutate(mex, NI = c(1, diff(Infectados))) # Nuevos infectados por día
mex
mex <- mutate(mex, NI = c(4, diff(Infectados))) # Nuevos infectados por día
mex
mex <- mutate(mex, NI = c(1, diff(Infectados))) # Nuevos infectados por día
mex <- mutate(mex, NM = c(0, diff(Muertos))) # Nuevos muertos por día
x
x <- rnorm(10)
x
diff(x)
x[1] - x[2]
mex <- mutate(mex, Letalidad = round(Muertos/Infectados*100, 1)) # Tasa de letalidad
mex
x
lag(x)
mex <- mutate(mex, IDA = lag(Infectados), MDA = lag(Muertos)) # Valores día anterior
mex <- mutate(mex, FCI = Infectados/IDA, FCM = Muertos/MDA) # Factores de Crecimiento
mex <- mutate(mex, Dia = 1:dim(mex)[1]) # Días de contingencia
mex
head(mex)
tail(mex)
View(mex)
max(select(mex, Letalidad))
cbind(1:10, 11:20, 21:30)
cbind(1:10, matrix(11:30, ncol =2))
cbind(data.frame(x = 1:10, y = 11:20), z = 21:30)
df1 <- data.frame(x = 1:5, y = 6:10, z = 16:20)
df2 <- data.frame(x = 51:55, y = 101:105, z = 151:155)
rbind(df1, df2)
rbind(df1, df2)
rbind(df2, df1)
X <- matrix(1:49, ncol = 7)
X
apply(X, 1, mean) # cálculo de la media para las filas
apply(X, 2, median) # cálculo de la mediana para las columnas
u1011 <- "https://www.football-data.co.uk/mmz4281/1011/SP1.csv"
u1112 <- "https://www.football-data.co.uk/mmz4281/1112/SP1.csv"
u1213 <- "https://www.football-data.co.uk/mmz4281/1213/SP1.csv"
u1314 <- "https://www.football-data.co.uk/mmz4281/1314/SP1.csv"
download.file(url = u1011, destfile = "data/SP1-1011.csv", mode = "wb")
download.file(url = u1112, destfile = "data/SP1-1112.csv", mode = "wb")
download.file(url = u1213, destfile = "data/SP1-1213.csv", mode = "wb")
download.file(url = u1314, destfile = "data/SP1-1314.csv", mode = "wb")
dir()
setwd("data")
dir()
lista <- lapply(dir(), read.csv) # Guardamos los archivos en lista
lista
download.file(url = u1011, destfile = "data/football/SP1-1011.csv", mode = "wb")
download.file(url = u1112, destfile = "data/football/SP1-1112.csv", mode = "wb")
download.file(url = u1213, destfile = "data/football/SP1-1213.csv", mode = "wb")
download.file(url = u1314, destfile = "data/football/SP1-1314.csv", mode = "wb")
download.file(url = u1011, destfile = "data/football/SP1-1011.csv", mode = "wb")
download.file(url = u1112, destfile = "data/football/SP1-1112.csv", mode = "wb")
download.file(url = u1213, destfile = "data/football/SP1-1213.csv", mode = "wb")
download.file(url = u1314, destfile = "data/football/SP1-1314.csv", mode = "wb")
u1011 <- "https://www.football-data.co.uk/mmz4281/1011/SP1.csv"
u1112 <- "https://www.football-data.co.uk/mmz4281/1112/SP1.csv"
u1213 <- "https://www.football-data.co.uk/mmz4281/1213/SP1.csv"
u1314 <- "https://www.football-data.co.uk/mmz4281/1314/SP1.csv"
download.file(url = u1011, destfile = "data/football/SP1-1011.csv", mode = "wb")
download.file(url = u1112, destfile = "data/football/SP1-1112.csv", mode = "wb")
download.file(url = u1213, destfile = "data/football/SP1-1213.csv", mode = "wb")
download.file(url = u1314, destfile = "data/football/SP1-1314.csv", mode = "wb")
setwd("D:/Documentos/BEDU/mod2/sesion02")
download.file(url = u1011, destfile = "data/football/SP1-1011.csv", mode = "wb")
download.file(url = u1112, destfile = "data/football/SP1-1112.csv", mode = "wb")
download.file(url = u1213, destfile = "data/football/SP1-1213.csv", mode = "wb")
download.file(url = u1314, destfile = "data/football/SP1-1314.csv", mode = "wb")
setwd("data/football")
dir()
lista <- lapply(dir(), read.csv) # Guardamos los archivos en lista
library(dplyr)
lista
head(lista)
str(lista)
library(dplyr)
lista <- lapply(lista, select, Date:FTR) # seleccionamos solo algunas columnas de cada data frame
lista <- lapply(lista, select, Date:FTR) # seleccionamos solo algunas columnas de cada data frame
lista
names(lista)
data <- do.call(rbind, lista)
head(data)
dim(data)
setwd("D:/Documentos/BEDU/mod2/sesion02/")
#Descargue los archivos csv que corresponden a las temporadas 2017/2018, 2018/2019, 2019/2020 y 2020/2021 de la Bundesliga 1 y que se encuentran en el siguiente enlace https://www.football-data.co.uk/germanym.php
u1011 <- "https://www.football-data.co.uk/mmz4281/1718/D1.csv"
u1112 <- "https://www.football-data.co.uk/mmz4281/1819/D1.csv"
u1213 <- "https://www.football-data.co.uk/mmz4281/1920/D1.csv"
u1314 <- "https://www.football-data.co.uk/mmz4281/2021/D1.csv"
download.file(url = u1011, destfile = "data/bundesliga/SP1-1011.csv", mode = "wb")
download.file(url = u1112, destfile = "data/bundesliga/SP1-1112.csv", mode = "wb")
download.file(url = u1213, destfile = "data/bundesliga/SP1-1213.csv", mode = "wb")
download.file(url = u1314, destfile = "data/bundesliga/SP1-1314.csv", mode = "wb")
#Importe los archivos descargados a R
setwd("data/bundesliga")
# Just if only CSV files exists on dir
allData <- lapply(dir(), read.csv) # read all files
selectedData <- lapply(select, allData)
# Just if only CSV files exists on dir
allData <- lapply(dir(), read.csv) # read all files
allData
selectedData <- lapply(select(, c(Date, HomeTeam, AwayTeam, FTHG, FTAG, FTR)), allData)
selectedData <- lapply(allData, select, c(Date, HomeTeam, AwayTeam, FTHG, FTAG, FTR))
selectedData
data <- do.call(rbind, selectedData)
data
dim(data)
is.data.frame(data)
library(rjson)
install.packages("rjson")
install.packages("XML")
library(rjson)
library(XML)
library(rjson)
library(XML)
URL1 <- "https://tools.learningcontainer.com/sample-json-file.json"
#URL1 <- "http://www.ipab.org.mx/ipab/datosabiertos?od=02-21"
JsonData <- fromJSON(file = URL1)
class(JsonData)
#URL1 <- "http://www.ipab.org.mx/ipab/datosabiertos?od=02-21"
JsonData <- fromJSON(file = URL1)
class(JsonData)
length(JsonData)
str(JsonData)
URL2 <- "http://www-db.deis.unibo.it/courses/TW/DOCS/w3schools/xml/cd_catalog.xml"
#URL2 <- "http://www.ipab.org.mx/ipab/datosabiertos?od=03-21"
xmlfile <- xmlTreeParse(URL2) # Parse the XML file. Analizando el XML
topxml <- xmlSApply(xmlfile, function(x) xmlSApply(x, xmlValue)) # Mostrando los datos de una forma amigable
xml_df <- data.frame(t(topxml), row.names= NULL) # Colocandolos en un Data Frame
str(xml_df) # Observar la naturaleza de las variables del DF
head(xml_df)
url3 <- URL2 # cargue el URL del XML
data_df <- xmlToDataFrame(url3)
head(data_df)
JsonData
str(JsonData)
xmlfile
topxml <- xmlSApply(xmlfile, function(x) xmlSApply(x, xmlValue)) # Mostrando los datos de una forma amigable
topxml
url3 <- URL2 # cargue el URL del XML
data_df <- xmlToDataFrame(url3)
head(data_df)
str(data_df)
head(airquality)
library(dplyr)
str(airquality)
dim(airquality)
dim(airquality)
bien <- complete.cases(airquality)
sum(bien)
airquality[bien,]
data <- select(airquality, Ozone:Temp)
data
apply(data, 2, mean)
apply(data, 2, mean, na.rm = T)
(m1 <- apply(na.omit(data), 2, mean))
b <- complete.cases(data)
(m2 <- apply(data[b,], 2, mean))
identical(m1, m2)
apply(data, 2, mean)
apply(data, 2, mean, na.rm = T)
(m1 <- apply(na.omit(data), 2, mean))
(m2 <- apply(data[b,], 2, mean))
identical(m1, m2)
